# DATA-ENGINEERING-TASK

DATA ENGINEERING TASK
You are provided with a dataset containing fields such as PORT, SB No, SB Details, IEC No, EGM, GST Details, Status, Gateway, ROSL, and other operational attributes.
Your task is to perform a set of data engineering activities in the exact order given below.
1)	PIVOT TABLES (Excel)
Create pivot tables that summarize and structure key information from the dataset.
Task Requirements:
•	Build pivot tables using fields such as PORT, Status, Gateway, GST Details, IEC, and others.
•	Each pivot table must include minimum two levels of grouping.
•	Include subtotals, grand totals, and clear headings.
•	Ensure pivot tables are neatly arranged and easy to interpret.
•	Maintain a clean layout without altering the raw source data.

2)	Power BI
Develop a Power BI dashboard that represents insights from the dataset.
Task Requirements:
•	Import the dataset into Power BI and clean it as needed.
•	Add multiple visuals including charts, matrix views, cards, or summary blocks.
•	Include slicers for fields such as PORT, IEC, Status, Gateway, EGM, and others.
•	Add a section that highlights overall operational metrics.
•	Arrange the visuals in a professional layout with proper spacing and labels.

3)	Complex Excel Formula
Use advanced formulas in Excel to derive new insights from the dataset.
Task Requirements:
•	Create new calculated fields using complex formulas involving lookup logic, conditional logic, or text/date functions.
•	Formulas must be meaningful and tied directly to the existing dataset columns.
•	At least three to five computed fields must be created.
•	Add proper column headers and ensure values generate automatically for all rows.
•	Keep the spreadsheet well-organized and readable.

4)	Small DBMS
Convert part of the dataset into a small structured database.
Task Requirements:
•	Create multiple database tables representing different components of the dataset such as shipment information, exporter details, compliance details, and status information.
•	Assign primary keys for each table and define relationships as needed.
•	Insert sample rows taken from the dataset into the tables.
•	Write SQL queries that retrieve combined, filtered, and sorted results.
•	Present queries clearly with proper formatting.

5)	Data Sorting
Sort the dataset using structured sorting techniques.
Task Requirements:
•	Perform sorting using multiple columns at once.
•	Create at least two differently sorted versions of the dataset.
•	Sorting should maintain row consistency and include fields such as PORT, Status, GST Details, IEC, Gateway, or EGM.
•	Save each sorted version separately and clearly label them.

6)	Docker
Set up a container environment to run your data processing workflow.
Task Requirements:
•	Create a Dockerfile that installs and prepares the tools or libraries required for your scripts.
•	Include your scripts, files, and any dependencies inside the container.
•	Ensure that the container executes your main script and produces an output file.
•	Provide clear instructions on how the container should be built and run.
7)	Selenium
Write an automation script that extracts structured information from a publicly accessible webpage.
Task Requirements:
•	Use Selenium to open a webpage containing structured or tabular information.
•	Extract relevant data points from the page.
•	Convert the extracted information into rows and columns.
•	Save the extracted information in a CSV file.
•	Ensure the script follows a consistent structure and extracts data accurately.

8)	Data Manipulation Using Python
Use Python to clean and transform the dataset.
Task Requirements:
•	Load the dataset using Python.
•	Perform data cleaning steps including but not limited to duplicate removal, formatting, data type correction, or trimming inconsistencies.
•	Apply necessary transformations like grouping, filtering, or creation of new fields.
•	Generate a final cleaned and processed dataset.
•	Save the processed dataset separately.

9)	Python Libraries
Use appropriate Python libraries for data manipulation and processing.
Task Requirements:
•	Use relevant libraries for reading, transforming, cleaning, and exporting data.
•	Organize the script into logical sections using clean variable names and structured code.
•	Ensure the script outputs meaningful results aligned with the dataset.




FINAL SUBMISSION STRUCTURE
Your final submission must include:
•	Pivot table outputs
•	Excel file with complex formulas
•	Power BI dashboard file
•	Database tables and SQL query file
•	Sorted dataset outputs
•	Dockerfile with execution instructions
•	Selenium script and extracted CSV
•	Python scripts and cleaned dataset

